{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bubblyboy/anybioinforma?scriptVersionId=236590575\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"41a4a9d2","metadata":{"papermill":{"duration":0.002779,"end_time":"2025-04-28T10:04:36.500632","exception":false,"start_time":"2025-04-28T10:04:36.497853","status":"completed"},"tags":[]},"source":["# ğŸ§¬ AnyBioInforma: Bioinformatics Research Assistant Using Gemini, FAISS & RAG\n","\n","## ğŸ”¬ Project Overview\n","\n","This notebook implements an intelligent **Bioinformatics Assistant** that helps researchers analyze **genomic data** using the power of Google's **Gemini model**, **vector search**, and **retrieval-augmented generation (RAG)**.\n","\n","The assistant is designed to:\n","\n","1. **Read and understand biomedical PDFs**, extracting scientific insights.  \n","2. **Build a semantic knowledge base** using chunked embeddings and FAISS vector storage.  \n","3. **Retrieve relevant scientific context** from the document corpus when answering queries.  \n","4. **Generate practical bioinformatics guidance**â€”not just theoretical answers.  \n","5. **Adapt responses in multiple languages** (English, Amharic, Arabic, Spanish) for global accessibility.\n","\n","---\n","\n","## ğŸŒ Multilingual Support\n","\n","The assistant supports the following languages:\n","\n","- English (`en`)  \n","- EspaÃ±ol (`es`)  \n","- Amharic (`am`)  \n","- Arabic (`ar`)\n","\n","Language-specific UI messages and prompts are handled via a `TEXTS` dictionary.\n","\n","---"]},{"cell_type":"code","execution_count":1,"id":"90b97cfd","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-04-28T10:04:36.506552Z","iopub.status.busy":"2025-04-28T10:04:36.506278Z","iopub.status.idle":"2025-04-28T10:05:30.045083Z","shell.execute_reply":"2025-04-28T10:05:30.044246Z"},"papermill":{"duration":53.545374,"end_time":"2025-04-28T10:05:30.048581","exception":false,"start_time":"2025-04-28T10:04:36.503207","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m437.2/437.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hConfiguration loaded. PDF Directory: /kaggle/input/bionformatis, FAISS Index Path: /kaggle/working/vectordb\n"]}],"source":["#Basic Configuration\n","!pip install --upgrade google-generativeai pypdf langchain langchain-core langchain-community faiss-cpu langchain-google-genai --quiet\n","import google.generativeai as genai\n","import pypdf\n","import os\n","import time\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings\n","from langchain_community.vectorstores import FAISS\n","import faiss\n","from kaggle_secrets import UserSecretsClient\n","\n","KAGGLE_DATASET_NAME = \"bionformatis\"\n","PDF_DIR = f\"/kaggle/input/{KAGGLE_DATASET_NAME}\"\n","FAISS_INDEX_PATH = \"/kaggle/working/vectordb\"\n","GEMINI_EMBEDDING_MODEL = \"models/embedding-001\"\n","GEMINI_GENERATIVE_MODEL = \"gemini-1.5-flash\"\n","CHUNK_SIZE = 1500\n","CHUNK_OVERLAP = 150\n","\n","# Language Configuration \n","selected_language = \"en\" \n","\n","LANGUAGES = {\n","    \"en\": \"English\",\n","    \"es\": \"EspaÃ±ol\",\n","    \"am\": \"áŠ áˆ›áˆ­áŠ›\",\n","    \"ar\": \"Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\"\n","}\n","\n","\n","TEXTS = {\n","    \"en\": {\n","        \"pdf_dir_not_found\": f\"ERROR: PDF directory '{PDF_DIR}' not found. Make sure the dataset '{KAGGLE_DATASET_NAME}' is attached.\",\n","        \"no_pdfs_found\": f\"WARNING: No PDF files found in '{PDF_DIR}'.\",\n","        \"error_reading_pdf\": \"ERROR: Error reading '{}': {}\",\n","        \"no_text_extracted\": \"ERROR: No text could be extracted from any PDF files.\",\n","        \"no_chunks_available\": \"ERROR: No text chunks available to create vector store.\",\n","        \"loading_index_failed\": \"WARNING: Failed to load existing FAISS index ({}). Rebuilding...\",\n","        \"setup_faiss_failed\": \"ERROR: Failed to setup FAISS vector store: {}\",\n","        \"vector_store_not_init\": \"ERROR: Vector store not initialized.\",\n","        \"retrieval_error\": \"ERROR: Error retrieving context from FAISS: {}\",\n","        \"response_generation_error\": \"ERROR generating response: {}\",\n","        \"api_key_needed\": \"ERROR: Google AI API Key not found in Kaggle Secrets. Please add it as 'GOOGLE_API_KEY'.\", # Updated message\n","        \"api_key_retrieval_error\": \"ERROR: Could not retrieve 'GOOGLE_API_KEY' from Kaggle Secrets: {}\", # New message\n","        \"invalid_api_key\": \"ERROR: Invalid API Key or configuration error: {}\",\n","        \"init_knowledge_base\": \"Initializing knowledge base...\",\n","        \"init_failed\": \"ERROR: Knowledge base initialization failed.\",\n","        \"ask_question\": \"Ask a question (or type 'quit' to exit): \",\n","        \"thinking\": \"Thinking...\",\n","        \"no_context_found\": \"I couldn't find relevant information in the documents to answer your question.\",\n","        \"sources\": \"Sources\",\n","        \"pdf_load_error\": \"ERROR: Failed to load or process PDFs. Cannot initialize chatbot.\" # Added missing key\n","    },\n","    \n","}\n","\n","current_texts = TEXTS.get(selected_language, TEXTS[\"en\"])\n","\n","print(f\"Configuration loaded. PDF Directory: {PDF_DIR}, FAISS Index Path: {FAISS_INDEX_PATH}\")\n"]},{"cell_type":"markdown","id":"8e641c64","metadata":{"papermill":{"duration":0.003126,"end_time":"2025-04-28T10:05:30.054625","exception":false,"start_time":"2025-04-28T10:05:30.051499","status":"completed"},"tags":[]},"source":["## âš™ï¸ Step 1: Configuration & Initialization\n","\n","This section sets up the environment by installing necessary packages, loading language-specific prompts and error messages, and preparing paths for PDF data and FAISS storage.\n","\n","**Key Libraries:**\n","- `google.generativeai` â€“ for LLM access (Gemini)  \n","- `langchain` â€“ for RAG framework and embedding utilities  \n","- `faiss-cpu` â€“ for building and querying the vector database  \n","- `pypdf` â€“ for PDF parsing and text extraction  \n"]},{"cell_type":"code","execution_count":2,"id":"7f5b8033","metadata":{"execution":{"iopub.execute_input":"2025-04-28T10:05:30.061247Z","iopub.status.busy":"2025-04-28T10:05:30.060879Z","iopub.status.idle":"2025-04-28T10:05:30.076881Z","shell.execute_reply":"2025-04-28T10:05:30.076168Z"},"papermill":{"duration":0.020856,"end_time":"2025-04-28T10:05:30.078082","exception":false,"start_time":"2025-04-28T10:05:30.057226","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Helper functions defined.\n"]}],"source":["# Helper Functions\n","\n","def load_and_process_pdfs():\n","    \"\"\"Loads PDFs from global PDF_DIR, extracts text, and splits into chunks.\"\"\"\n","    pdf_directory = PDF_DIR\n","    all_texts = []\n","    if not os.path.exists(pdf_directory):\n","        print(current_texts[\"pdf_dir_not_found\"])\n","        return None, None\n","\n","    pdf_files = [f for f in os.listdir(pdf_directory) if f.lower().endswith(\".pdf\")]\n","    if not pdf_files:\n","        print(current_texts[\"no_pdfs_found\"])\n","        return None, None\n","\n","    print(f\"Found {len(pdf_files)} PDF(s) in '{pdf_directory}'. Processing...\")\n","    for i, filename in enumerate(pdf_files):\n","        filepath = os.path.join(pdf_directory, filename)\n","        try:\n","            reader = pypdf.PdfReader(filepath)\n","            file_text = \"\"\n","            for page_num, page in enumerate(reader.pages):\n","                page_text = page.extract_text()\n","                if page_text:\n","                    file_text += page_text + \"\\n\"\n","            if file_text:\n","                all_texts.append({\"filename\": filename, \"content\": file_text})\n","                print(f\"  Processed '{filename}'\")\n","            else:\n","                 print(f\"  WARNING: Could not extract text from '{filename}'. Skipping.\")\n","        except Exception as e:\n","            print(current_texts[\"error_reading_pdf\"].format(filename, e))\n","\n","    if not all_texts:\n","        print(current_texts[\"no_text_extracted\"])\n","        return None, None\n","\n","    print(\"Splitting documents into chunks...\")\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=CHUNK_SIZE,\n","        chunk_overlap=CHUNK_OVERLAP,\n","        length_function=len,\n","    )\n","\n","    all_chunks = []\n","    metadatas = []\n","    for doc in all_texts:\n","        chunks = text_splitter.split_text(doc[\"content\"])\n","        for chunk_idx, chunk in enumerate(chunks):\n","            all_chunks.append(chunk)\n","            metadatas.append({\"source\": doc[\"filename\"], \"chunk\": chunk_idx})\n","\n","    print(f\"Created {len(all_chunks)} chunks.\")\n","    return all_chunks, metadatas\n","\n","def setup_faiss_vector_store(chunks, metadatas, api_key):\n","    \"\"\"Creates or loads a FAISS vector store with Gemini embeddings.\"\"\"\n","    if not chunks or not metadatas:\n","        print(current_texts[\"no_chunks_available\"])\n","        return None\n","\n","    try:\n","        embeddings = GoogleGenerativeAIEmbeddings(model=GEMINI_EMBEDDING_MODEL, google_api_key=api_key)\n","\n","        if os.path.exists(FAISS_INDEX_PATH):\n","            try:\n","                print(f\"Attempting to load existing FAISS index from {FAISS_INDEX_PATH}...\")\n","                vector_store = FAISS.load_local(\n","                    FAISS_INDEX_PATH,\n","                    embeddings,\n","                    allow_dangerous_deserialization=True\n","                )\n","                print(\"FAISS index loaded successfully.\")\n","                return vector_store\n","            except Exception as load_e:\n","                print(current_texts[\"loading_index_failed\"].format(load_e))\n","\n","        print(f\"Creating new FAISS index ({len(chunks)} chunks)...\")\n","        start_time = time.time()\n","        vector_store = FAISS.from_texts(chunks, embedding=embeddings, metadatas=metadatas)\n","        end_time = time.time()\n","        print(f\"FAISS index created in {end_time - start_time:.2f} seconds.\")\n","\n","        print(f\"Saving FAISS index to {FAISS_INDEX_PATH}...\")\n","        vector_store.save_local(FAISS_INDEX_PATH)\n","        print(\"FAISS index saved.\")\n","        return vector_store\n","\n","    except Exception as e:\n","        print(current_texts[\"setup_faiss_failed\"].format(e))\n","        return None\n","\n","def get_relevant_context(query, vector_store, n_results=5):\n","    \"\"\"Retrieves relevant context from FAISS vector store.\"\"\"\n","    if not vector_store:\n","        print(current_texts[\"vector_store_not_init\"])\n","        return [], []\n","    try:\n","        print(f\"Searching for relevant context for query: '{query}'\")\n","        results_with_scores = vector_store.similarity_search_with_score(query, k=n_results)\n","        context_docs = [doc.page_content for doc, score in results_with_scores]\n","        context_metadatas = [doc.metadata for doc, score in results_with_scores]\n","        print(f\"Retrieved {len(context_docs)} context snippets.\")\n","        return context_docs, context_metadatas\n","    except Exception as e:\n","        print(current_texts[\"retrieval_error\"].format(e))\n","        return [], []\n","\n","def generate_response(query, context_docs, context_metadatas, api_key, language=\"en\"):\n","    \"\"\"Generates response using Gemini based on query, context, and language.\"\"\"\n","    try:\n","        model = genai.GenerativeModel(GEMINI_GENERATIVE_MODEL)\n","\n","        context_string = \"\"\n","        sources = set()\n","        for doc, meta in zip(context_docs, context_metadatas):\n","            source_file = meta.get('source', 'Unknown source')\n","            context_string += f\"Source: {source_file}\\nContent:\\n{doc}\\n\\n---\\n\\n\"\n","            sources.add(source_file)\n","\n","        language_name = LANGUAGES.get(language, \"English\")\n","        prompt = f\"\"\"You are a helpful assistant knowledgeable in bioinformatician assisting a biomedical research in a practical analysis of genomic data, answering questions based on the provided text snippets\n","\n","        In your  response you will be giving a practical assistance. To enable the researcher to make full use of your knowledge you will give a quick introduction on how these particular analysis will be structured. \n","        The response will be a combination of responding with the theory and how to perform bioinformatic analysis on real data.\n","\n","        Sections will be labelled according to its intended purpose and are described below:\n","\n","        General text:\n","\n","            Text which does not have any special formatting and looks (plain) like this will guide you through the practicals, providing background and explaining what anlyses we are performing, and why.\n","            Checkpoints\n","            Text which appears in boxes of this colour aims to inform you of a significant checkpoint in your analysis. When you see this, it is good to take a moment to think about what you have acomplished so far and what you have yet to do.\n","        \n","        Code:\n","\n","            Text which appears in boxes of this colour will tell that you are looking at a terminal command.\n","            You can copy and paste from here straight to the terminal but before you do take a moment to understand what the command is actually doing.\n","            Several command lines may be present, with each new line representing a single command. \n","\n","        Screen output:\n","\n","            Text appearing in these boxes represents output you might expect to see in the terminal in response to a command.\n","            Check to see if you get a similar output!\n","\n","        Questions:\n","            Text in these boxes will usually ask an open ended question.\n","\n","        Answer:\n","            You can answer the above questions in the text boxes provided.\n","\n","\n","**Please provide the answer in {language_name}.**\n","\n","Context from documents:\n","{context_string}\n","\n","Question:\n","{query}\n","\n","Answer ({language_name}):\n","\"\"\"\n","        print(\"Generating response...\")\n","        start_time = time.time()\n","        response = model.generate_content(prompt)\n","        end_time = time.time()\n","        print(f\"Response generated in {end_time - start_time:.2f} seconds.\")\n","\n","        response_text = response.text\n","\n","        return response_text\n","\n","    except Exception as e:\n","        print(current_texts[\"response_generation_error\"].format(e))\n","        return \"Sorry, I encountered an error while generating the response.\"\n","\n","print(\"Helper functions defined.\")"]},{"cell_type":"markdown","id":"4c74eb1b","metadata":{"papermill":{"duration":0.003746,"end_time":"2025-04-28T10:05:30.084502","exception":false,"start_time":"2025-04-28T10:05:30.080756","status":"completed"},"tags":[]},"source":["## ğŸ“‚ Step 2: PDF Loading & Text Chunking\n","\n","The function `load_and_process_pdfs()` scans a specified directory of biomedical PDFs and:\n","\n","1. **Reads all pages** of each file using `pypdf`.  \n","2. **Extracts plain text**, skipping unreadable files.  \n","3. **Splits the text into overlapping chunks** using LangChainâ€™s `RecursiveCharacterTextSplitter`.\n","\n","These chunks serve as the foundation for building a searchable semantic knowledge base.\n","\n","## ğŸ§  Step 3: FAISS Vector Store Setup\n","\n","The function `setup_faiss_vector_store()` handles vectorization and indexing:\n","\n","- **Creates embeddings** using Googleâ€™s `embedding-001` model.  \n","- **Loads or builds** a FAISS index of the chunked documents.  \n","- **Persists the index** to disk so it can be reused in future sessions.\n","\n","If an index exists, it will try to load it firstâ€”otherwise it will create a new one from scratch.\n","\n","\n","## ğŸ” Step 4: Semantic Search with FAISS\n","\n","The `get_relevant_context()` function uses semantic similarity to:\n","\n","- **Search the FAISS index** using the userâ€™s query.  \n","- **Return the most relevant chunks and metadata**, providing context for response generation.\n","\n","This is the retrieval part of the RAG framework.\n"]},{"cell_type":"code","execution_count":3,"id":"1c938a1b","metadata":{"execution":{"iopub.execute_input":"2025-04-28T10:05:30.090693Z","iopub.status.busy":"2025-04-28T10:05:30.090482Z","iopub.status.idle":"2025-04-28T10:05:48.13117Z","shell.execute_reply":"2025-04-28T10:05:48.130283Z"},"papermill":{"duration":18.045304,"end_time":"2025-04-28T10:05:48.132403","exception":false,"start_time":"2025-04-28T10:05:30.087099","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["API Key retrieved from Kaggle Secrets.\n","Checking API key validity...\n","API key configured successfully.\n","Initializing knowledge base...\n","Found 1 PDF(s) in '/kaggle/input/bionformatis'. Processing...\n","  Processed 'Bioinformatics_for_Beginners_2014.pdf'\n","Splitting documents into chunks...\n","Created 583 chunks.\n","Creating new FAISS index (583 chunks)...\n","FAISS index created in 10.18 seconds.\n","Saving FAISS index to /kaggle/working/vectordb...\n","FAISS index saved.\n","Knowledge base initialized successfully in 17.56 seconds.\n"]}],"source":["# API Key Handling and Initialization\n","\n","api_key = None\n","initialization_successful = False\n","faiss_vector_store = None\n","\n","try:\n","    user_secrets = UserSecretsClient()\n","    api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n","    if not api_key:\n","         print(current_texts[\"api_key_needed\"])\n","    else:\n","         print(\"API Key retrieved from Kaggle Secrets.\")\n","except Exception as e:\n","    print(current_texts[\"api_key_retrieval_error\"].format(e))\n","    api_key = None \n","\n","if not api_key:\n","    print(\"Stopping execution as API key is missing or could not be retrieved.\")\n","else:\n","    try:\n","        genai.configure(api_key=api_key)\n","        print(\"Checking API key validity...\")\n","        list(genai.list_models())\n","        print(\"API key configured successfully.\")\n","\n","        # --- Initialization ---\n","        print(current_texts[\"init_knowledge_base\"])\n","        init_start_time = time.time()\n","        chunks, metadatas = load_and_process_pdfs()\n","        \n","        if chunks is None or metadatas is None:\n","             print(current_texts[\"pdf_load_error\"])\n","        elif chunks and metadatas:\n","            faiss_vector_store = setup_faiss_vector_store(chunks, metadatas, api_key)\n","            if faiss_vector_store:\n","                initialization_successful = True\n","        else:\n","             print(current_texts[\"no_chunks_available\"])\n","\n","\n","        init_end_time = time.time()\n","\n","        if not initialization_successful or not faiss_vector_store:\n","            if not (chunks and metadatas):\n","                 pass\n","            elif not faiss_vector_store:\n","                  pass\n","            else:\n","                 print(current_texts[\"init_failed\"])\n","        else:\n","            print(f\"Knowledge base initialized successfully in {init_end_time - init_start_time:.2f} seconds.\")\n","\n","    except Exception as e:\n","        print(current_texts[\"invalid_api_key\"].format(e))\n","        initialization_successful = False\n"]},{"cell_type":"markdown","id":"f1e3aacf","metadata":{"papermill":{"duration":0.00269,"end_time":"2025-04-28T10:05:48.138256","exception":false,"start_time":"2025-04-28T10:05:48.135566","status":"completed"},"tags":[]},"source":["## ğŸ’¬ Step 5: Gemini-Powered Bioinformatics Q&A\n","\n","The core function `generate_response()` combines the userâ€™s query with the retrieved context to:\n","\n","1. Build a **context-aware prompt** tailored for bioinformatics tasks.  \n","2. Ask the Gemini model to act like a **practical research assistant**.  \n","3. Include structured guidance on analysis, checkpoints, code, screen output, and questions.  \n","4. Generate a **multilingual, practical answer** for hands-on genomics work."]},{"cell_type":"code","execution_count":4,"id":"c884288e","metadata":{"execution":{"iopub.execute_input":"2025-04-28T10:05:48.144785Z","iopub.status.busy":"2025-04-28T10:05:48.144549Z","iopub.status.idle":"2025-04-28T10:05:48.15495Z","shell.execute_reply":"2025-04-28T10:05:48.154337Z"},"papermill":{"duration":0.014973,"end_time":"2025-04-28T10:05:48.156097","exception":false,"start_time":"2025-04-28T10:05:48.141124","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Starting Chat ---\n","Type 'quit' to exit.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cbbb6deedd3446c49ea4dd60d084c3e2","version_major":2,"version_minor":0},"text/plain":["Text(value='', description='You:', placeholder='Type your question here...')"]},"metadata":{},"output_type":"display_data"}],"source":["import ipywidgets as widgets\n","from IPython.display import display, clear_output\n","\n","chat_history = []\n","\n","# Only run this if initialization is successful\n","if initialization_successful and faiss_vector_store:\n","    print(\"\\n--- Starting Chat ---\")\n","    print(\"Type 'quit' to exit.\")\n","\n","    text_input = widgets.Text(\n","        value='',\n","        placeholder='Type your question here...',\n","        description='You:',\n","        disabled=False\n","    )\n","\n","    display(text_input)\n","\n","    def on_submit(change):\n","        prompt = change['new'].strip()\n","        if prompt.lower() == 'quit':\n","            print(\"Exiting chat.\")\n","            text_input.disabled = True\n","            return\n","\n","        if not prompt:\n","            return\n","\n","        chat_history.append({\"role\": \"user\", \"content\": prompt})\n","\n","        print(f\"\\nYou: {prompt}\")\n","        print(current_texts[\"thinking\"])\n","\n","        context_docs, context_metadatas = get_relevant_context(prompt, faiss_vector_store)\n","\n","        if not context_docs:\n","            full_response = current_texts[\"no_context_found\"]\n","        else:\n","            full_response = generate_response(prompt, context_docs, context_metadatas, api_key, selected_language)\n","\n","        print(f\"\\nAssistant: {full_response}\")\n","        chat_history.append({\"role\": \"assistant\", \"content\": full_response})\n","\n","        # Clear text input for next question\n","        text_input.value = ''\n","\n","    text_input.observe(on_submit, names='value')\n","\n","else:\n","    print(\"\\nChat cannot start. Please check initialization steps in previous cells for errors.\")\n"]},{"cell_type":"markdown","id":"91454ed5","metadata":{"papermill":{"duration":0.002792,"end_time":"2025-04-28T10:05:48.161856","exception":false,"start_time":"2025-04-28T10:05:48.159064","status":"completed"},"tags":[]},"source":["## ğŸ’¡ Key GenAI Concepts Demonstrated\n","\n","- **RAG (Retrieval-Augmented Generation)**: Combines search + generation.  \n","- **FAISS indexing**: Fast similarity search over vectorized documents.  \n","- **PDF parsing and chunking**: Real-world biomedical content ingestion.  \n","- **Multilingual prompts**: Localized experience for researchers worldwide.  \n","- **Practical prompt engineering**: Tailored output for bioinformatics workflows.\n","\n","---\n","## ğŸš€ Final Thoughts\n","\n","This project demonstrates how **Generative AI + Semantic Search** can empower life science researchers to:\n","\n","- Get **hands-on assistance** with their genomic pipelines.  \n","- Leverage complex scientific texts effortlessly.  \n","- Ask questions in **natural language** and get **practical responses** grounded in real documents."]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":7201144,"sourceId":11488509,"sourceType":"datasetVersion"},{"datasetId":7206393,"sourceId":11495739,"sourceType":"datasetVersion"}],"dockerImageVersionId":31012,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":81.342923,"end_time":"2025-04-28T10:05:51.33446","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-28T10:04:29.991537","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"1ea4c0f372e54daa8f4a3528b727b100":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"TextStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"TextStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"4a3d149c72e5455697e309e5ba044a52":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbbb6deedd3446c49ea4dd60d084c3e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"TextModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"TextView","continuous_update":true,"description":"You:","description_allow_html":false,"disabled":false,"layout":"IPY_MODEL_4a3d149c72e5455697e309e5ba044a52","placeholder":"Type your question here...","style":"IPY_MODEL_1ea4c0f372e54daa8f4a3528b727b100","tabbable":null,"tooltip":null,"value":""}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}